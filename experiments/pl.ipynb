{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import os, sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from PIL import Image\n",
    "sys.path.append('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda'\n",
    "clip_model_name = 'ViT-L/14'\n",
    "clip_models_path = '/f/stablediffusion/stable-diffusion-webui/models/clip-interrogator'\n",
    "blip_image_eval_size = 384\n",
    "dtype = 'float32'\n",
    "\n",
    "# from modules/interrogate.py\n",
    "def load_clip_model():\n",
    "\timport clip\n",
    "\tmodel, preprocess = clip.load(clip_model_name)\n",
    "\tmodel.eval()\n",
    "\tmodel = model.to(device)\n",
    "\treturn model, preprocess\n",
    "\n",
    "def preprocess_img(preprocess, pil_image):\n",
    "\t\tclip_image = preprocess(pil_image).unsqueeze(0).type(dtype).to(device)\n",
    "\t\treturn clip_image\n",
    "\n",
    "def encode_image(clip_model, clip_image):\n",
    "\timage_features = clip_model.encode_image(clip_image).type(dtype)\n",
    "\treturn image_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = load_clip_model()\n",
    "clip_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = model\n",
    "device = 'cuda'\n",
    "dtype = torch.float32\n",
    "text = 'a photo of a cat wearing a pink hat on a blue rug'\n",
    "text_array = text.split(' ')\n",
    "text_token_list = [clip.tokenize(x, truncate=True).to(device) for x in text_array]\n",
    "empty_token = clip.tokenize('', truncate=True).to(device)\n",
    "text_feature_list = [clip_model.encode_text(t).type(dtype) for t in text_token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtext_feature_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "text_feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_10 = Image.open('images/10.png')\n",
    "img_10_features = encode_image(model, preprocess_img(preprocess, img_10))\n",
    "img_30 = Image.open('images/30.png')\n",
    "img_30_features = encode_image(model, preprocess_img(preprocess, img_30))\n",
    "\n",
    "# %%markdown\n",
    "# ![title](images/10.png)\n",
    "# ![title](images/30.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768]),\n",
       " torch.Size([1, 768])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in text_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
